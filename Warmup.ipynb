{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm-Up\n",
    "\n",
    "Start by running the usual Library Import cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load URLs from CSV\n",
    "\n",
    "Run the following line to download the `urls.csv` file to your folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://wagon-public-datasets.s3.amazonaws.com/02-Data-Toolkit/02-Data-Sourcing/urls.csv > urls.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then load this CSV in a `urls_df` dataframe using Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrich Dataset with an API\n",
    "\n",
    "Let's use the `fetch_metadata` function that we just implemented in the `opengraph.py` file.\n",
    "\n",
    "First let's import it and make sure that it works in the Notebook. \n",
    "\n",
    "1. Write the relevant `from ... import ...` line\n",
    "1. Call the `fetch_metadata` on a URL of your choice. You can write `fetch_` then `<TAB>` to autocomplete, then `<SHIFT> + <TAB>` to view the Docstring from your Python file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over the `urls_df` dataframe to add `title` and `description` columns for each URL\n",
    "\n",
    "<details>\n",
    "  <summary>ðŸ†˜ Hint</summary>\n",
    "\n",
    "  <p>Have a look at today's Lecture, you can start by copy/pasting what we did for <code>tracks_df</code> and adapt the code</p>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check your code!\n",
    "\n",
    "Run the cell below to check your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('warmup',\n",
    "    df_columns=urls_df.columns,\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Autoreload\n",
    "\n",
    "Today's Lecture introduced you to the usefulness of [`autoreload`](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html) in the notebook, let's experiment with it!\n",
    "\n",
    "Run the following cell, it should return `True` if your method returns `{}` when a website is not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_metadata(\"https://www.a.com\") == {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open VS Code and change the behavior of the function, to make it return an empty string `\"\"` rather than `{}` if the HTTP response is something else than `200`. Save your file on the drive, and re-run the cell above.\n",
    "\n",
    "Do you see something changing? No? That's normal! The first version of the `fetch_metadata` code is stored in the Notebook Kernel.\n",
    "\n",
    "---\n",
    "\n",
    "OK, let's change back the `fetch_metadata` code in VS Code back to `{}`.\n",
    "\n",
    "Then, add the following two lines to your first Notebook code cell:\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "```\n",
    "\n",
    "Then in the menu bar, go to `Kernel` > `Restart & Run all`.\n",
    "\n",
    "---\n",
    "\n",
    "Now that autoreload is enabled, go to VS Code, and once again change the behavior so that it returns an empty string. Re-run the code cell above. Do you get `False`? Good! That means that the Notebook is now monitoring changes to the files imported, like `opengraph.py`, and will reload them if the code within them changes!\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "You might find this confusing, jumping through Notebook and VS Code, don't worry you will get used to it. The Notebook is a perfect tool to experiment, to keep notes, to get graphical output of the data, etc. Still, the end goal of a Data Team is to **ship** something (a product, an API, a model, etc.), so productizing the code and refactoring it _out_ of the Notebook into proper Python modules is a critical skill that you will learn!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
